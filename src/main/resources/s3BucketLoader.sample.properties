#################################
# S3BucketLoader config file
#################################

# name prefix for the 'control channel' SNS topic
# that will be created to coordinate workers
aws.sns.control.topic.name=s3BucketLoaderControlChannel

# name of the SQS 'table of contents' queue
# that all workers consume from
aws.sqs.queue.name=s3BucketLoaderTOCQueue

# AWS creds to manage the above resources
# You will need to tweak this user's IAM 
# policies to permit appropriate SNS/SQS access
aws.access.key=YOUR_ACCESS_KEY
aws.secret.key=YOUR_SECRET_KEY
aws.account.principal.id=121212121221
aws.user.arn=arn:aws:iam::121212121221:user/your.s3bucketLoader.username


############################
# MASTER mode configs
# - will only be consumed
#   if -DisMaster=true is set
############################

# SourceTOCGenerator - the class used to generate
# the 'table of contents', the default is this DirectoryCrawler
# which will scan the 'source.dir' configured below
tocGenerator.class=org.bitsofinfo.s3.toc.DirectoryCrawler
tocGenerator.source.dir=/opt/nfs/toc_source

# total number of workers we expect to be running
# and consuming the toc tasks we create. The higher
# this number the faster it all works... you just
# need to provide and launch the workers... which
# if you turn 'master.workers.ec2.managed=true' on
# will be much more seamless (and cost you $$)
# NOTE: the master will not start publishing the TOC
# until this number of workers have reported as
# initialized. (if using ec2, the master has logic
# to detect and auto-terminate suspect workers that
# have yet to report in, to keep things moving
master.workers.total=4

# number of threads which consume
# the TOC entries the TOC generator creates and
# dispatch them to the SQS TOC queue. 
master.tocqueue.dispatch.threads=8

# Workers send period 'current' summary
# messages over the control channel which contain
# stats on the number of successes/fails for both
# WRITE and VALIDATE modes, if any of these 
# CURRENT_SUMMARY contain failures this setting
# controls if the master will stop the writes/validations
# currently in progress and immediately switch 
# to REPORT_ERRORS mode.... If this is false
# master will only go into ERROR_REPORT mode
# when workers are complete and send their FINISHED_SUMMARY
master.failfast.on.worker.current.summary.error=true

# OPTIONAL, this will use workers.total to spin up ec2 instances
# otherwise you are responsible for setting up workers
# and getting them ready. If you use this it can cost
# you $$ and you will want to use the userDataFile
# contents to automate the 'setup' of your worker nodes
master.workers.ec2.managed=false
master.workers.ec2.minutes.to.wait.for.worker.init=10
master.workers.ec2.ami.id=ami-08842d60
master.workers.ec2.instanceType=t2.micro
master.workers.ec2.disk.deviceName=/dev/xvda
master.workers.ec2.disk.volumeType=Standard
master.workers.ec2.disk.size.gigabytes=30
master.workers.ec2.keyName=myKey
master.workers.ec2.securityGroupId=sg-3a8d065f
master.workers.ec2.subnetId=subnet-80d1f3a8
master.workers.ec2.shutdownBehavior=Terminate
master.workers.ec2.userDataFile=/path/to/ec2-init-s3BucketLoader.py


############################
# WORKER mode configs
# - will only be consumed
#   if -DisMaster=false is set
############################

# Total number of SQS TOC queue 
# consumer threads that will run
# on each worker node. You will want
# to tweak this based on the number of 
# cores your worker boxes have. Also
# consider that if you are ultimately writing
# through yas3fs, you have to account for 
# the threads yas3fs can potentially need
# as well. 
worker.toc.consumer.threads.num=4

# OPTIONAL: woker initialize command
# this will be run before the worker
# reports itself as INITIALIZED
# in this example we fire up yas3fs
# on the node to mount the target S3 
# bucket that the worker node(s) will 
# write to. This obviously assumes that your
# worker has the software required to run
# the comamnds below....@see 'master.workers.ec2.userDataFile'
worker.initialize.cmd=/path/to/yas3fs s3://BUCKET-NAME /opt/s3BucketLoader -l /path/to/yas3fs.log -d --st-blksize 131072 --read-retries-num 10 --read-retries-sleep 1 --download-retries-num 20 --download-retries-sleep 5 --recheck-s3 --cache-path /path/to/yas3fs/cache/s3BucketLoader --cache-on-disk 0 --cache-disk-size 30000 --with-plugin-class RecoverYas3fsPlugin --aws-managed-encryption --log-backup-count 20 --log-backup-gzip --log-mb-size 100
worker.initialize.cmd.env=AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY,AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY
worker.destroy.cmd=fusermount -u /opt/s3BucketLoader

# OPTIONAL: a 'writeBackoffMonitor" which monitors 
# yas3fs to determine when to backoff based on
# checking the s3_queue number, if it gets to a certain
# point all TOCQueue consuming threads will pause until
# s3_queue drops (yas3fs writes in background and we don't
# want to overload it)
worker.write.backoff.monitor.class=org.bitsofinfo.s3.yas3fs.Yas3fsS3UploadMonitor
worker.write.backoff.monitor.yas3fs.backoffWhenTotalS3Uploads=10
worker.write.backoff.monitor.yas3fs.checkEveryMS=30000
worker.write.backoff.monitor.yas3fs.logFilePath=/path/to/yas3fs.log


# OPTIONAL: a 'writeMonitor" which monitors 
# yas3fs to determine when it is really complete
# with all background uploads (checks s3_queue status
# for N number of times for it being consistently zero (0)
# All rsyncs can finish, yet yas3fs could be uploading in 
# the background...
worker.write.complete.monitor.class=org.bitsofinfo.s3.yas3fs.Yas3fsS3UploadMonitor
worker.write.complete.monitor.yas3fs.checkEveryMS=30000
worker.write.complete.monitor.yas3fs.logFilePath=/path/to/yas3fs.log

# TOCPayloadHandler - there are two TOC 
# payload handlers for both modes (WRITE/VALIDATE)
# For each consumed TOC message, these are invoked
# depending on the mode (i.e. copying from source.dir -> target.dir)
# or checking for file existance and size during validate
# FileCopyTOCPayloadHandler does (mkdir -p + (rsync | cp) + (optional chown/chmod))
tocPayloadHandler.write.class=org.bitsofinfo.s3.toc.FileCopyTOCPayloadHandler

# number of retries for each FileCopy operation (mkdir, rsync | cp) etc
tocPayloadHandler.write.retries=3
tocPayloadHandler.write.retries.sleep.ms=5000

# if set to FALSE, will just exec a standard "cp"
tocPayloadHandler.write.use.rsync=true

# rsync options, note this will be split on spaces
# when its time to parse it
tocPayloadHandler.write.rsync.options=--inplace -avz

# optional regex for permissible rsync errors that will be ignored and not reported
# for example this this case the TOC source where paths are generated may be newer
# than the copy the workers have, so we don't expect them all to work.
tocPayloadHandler.write.rsync.tolerable.error.regex=(?s)(.*change_dir.*\\/opt\\/nfs.*No such file or directory.*)

# OPTIONAL for FileCopyTOCPayloadHandler
# these will be executed after the copy
# of each file path, and configurable if to
# be applied to directories ONLY or both files/dirs
tocPayloadHandler.write.chmod.dirsOnly=true
tocPayloadHandler.write.chmod=775 
tocPayloadHandler.write.chown.dirsOnly=true
tocPayloadHandler.write.chown=500:500

# for VALIDATE mode, this one by default checks file existence AND size match up
tocPayloadHandler.validate.class=org.bitsofinfo.s3.toc.ValidatingTOCPayloadHandler

# This dir should have access to the shared copy of 
# source data that the TOC was generated from
tocPayloadHandler.source.dir.root=/opt/nfs/toc_source

# This dir should be the 'target' dir of where
# the files will be copied to (i.e. this would be the yas3fs s3 mount root)
tocPayloadHandler.target.dir.root=/opt/s3BucketLoader


 
